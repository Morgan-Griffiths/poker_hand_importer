{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from utils import state_mapping\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self,head_size,n_embd,block_size,dropout):\n",
    "        super().__init__()\n",
    "        self.head_size = head_size\n",
    "        self.keys = nn.Linear(n_embd,head_size,bias=False)\n",
    "        self.queries = nn.Linear(n_embd,head_size,bias=False)\n",
    "        self.values = nn.Linear(n_embd,head_size,bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('tril',torch.tril(torch.ones((block_size,block_size))))\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        # x.shape = B,T,C\n",
    "        B,T,C = x.shape\n",
    "        k = self.keys(x)\n",
    "        q = self.queries(x)\n",
    "        v = self.values(x)\n",
    "        qk = (q @ einops.rearrange(k,'b t c -> b c t')) * self.head_size**0.5 # (b t t)\n",
    "        qk = qk.masked_fill(self.tril[:T,:T] == 0,float('-inf'))\n",
    "        qk = F.softmax(qk,dim=-1)\n",
    "        qk = self.dropout(qk)\n",
    "        out = qk @ v # (b t c)\n",
    "        return out\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self,n_heads,head_size,n_embd,dropout,block_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([SelfAttention(head_size,n_embd,block_size,dropout) for _ in range(n_heads)])\n",
    "        self.projection = nn.Linear(n_embd,n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = torch.cat([h(x) for h in self.heads],dim=-1)\n",
    "        out = self.dropout(self.projection(out))\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self,n_embd,dropout):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd,4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd,n_embd),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self,n_embd,n_heads,dropout,block_size):\n",
    "        super().__init__()\n",
    "        self.head = MultiHeadedAttention(n_heads,n_embd//n_heads,n_embd,dropout,block_size)\n",
    "        self.ff = FeedForward(n_embd,dropout)\n",
    "        self.layernorm1 = nn.LayerNorm(n_embd)\n",
    "        self.layernorm2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x + self.head(self.layernorm1(x))\n",
    "        x = x + self.ff(self.layernorm2(x))\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self,n_embd,n_heads,dropout,block_size,action_size,n_layers):\n",
    "        super().__init__()\n",
    "        self.tblocks = nn.Sequential(\n",
    "            *[TransformerBlock(n_embd,n_heads,dropout,block_size) for _ in range(n_layers)]\n",
    "            )\n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd,action_size)\n",
    "        self.emb_position = nn.Embedding(7, 6, padding_idx=0)\n",
    "        self.emb_action = nn.Embedding(12, 6, padding_idx=0)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\" \n",
    "        state.shape = (B,T,49)\n",
    "        T = 24 (max length of game)\n",
    "        Game state is a vector of length 49\n",
    "        We combine the T and state dimensions -> (B,T*49)\n",
    "        This becomes our B by tokens input to the transformer.\n",
    "        \"\"\"\n",
    "        B, M, C = state.shape\n",
    "        stats = state.float()\n",
    "        pot = state[:, :, state_mapping[\"pot\"]] # (B, T, 1)\n",
    "        amnt_to_call = state[:, :, state_mapping[\"amount_to_call\"]] # (B, T, 1)\n",
    "        previous_amount = state[:, :, state_mapping[\"previous_amount\"]] # (B, T, 1)\n",
    "        action = self.emb_action(state[:, :, state_mapping[\"previous_action\"]].long()) # (B, T, 6)\n",
    "        position = self.emb_position(\n",
    "            state[:, :, state_mapping[\"previous_position\"]].long()\n",
    "        ) # (B, T, 6)\n",
    "        x = torch.cat([pot.unsqueeze(-1), amnt_to_call.unsqueeze(-1), previous_amount.unsqueeze(-1), action, position], dim=-1).float() # (B, T, 3 + 6 + 6)\n",
    "        # We flatten the sequence and convert the input to a (B, 15 * 24) tensor\n",
    "        x = self.tblocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        x = self.lm_head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from models import Simple,Transformer\n",
    "from torch.optim import AdamW\n",
    "import torch.nn.functional as F\n",
    "from config import Config\n",
    "import torch\n",
    "\n",
    "\n",
    "def train_network(training_params, game_states, target_actions, target_rewards,config):\n",
    "    model = Transformer(config.n_embd,config.n_heads,config.dropout,config.block_size,config.action_size,config.n_layers)\n",
    "    optimizer = AdamW(model.parameters(), lr=0.003)\n",
    "    for e in range(training_params[\"epochs\"]):\n",
    "        out = model(game_states)\n",
    "        print(\"out\", out.shape)\n",
    "        loss = F.cross_entropy(out[:,-1,:], target_actions)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss.item())\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = Config()\n",
    "config.n_embd = 15\n",
    "config.n_heads = 3\n",
    "training_params = {\n",
    "    \"epochs\": 10,\n",
    "}\n",
    "game_states = torch.from_numpy(np.load(\"data/states.npy\"))\n",
    "target_actions = torch.from_numpy(np.load(\"data/actions.npy\") - 1)\n",
    "target_rewards = torch.from_numpy(np.load(\"data/rewards.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 49])\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n",
      "{'hand_range': [0, 8], 'board_range': [8, 18], 'street': 18, 'num_players': 19, 'hero_pos': 20, 'hero_active': 21, 'vil1_active': 22, 'vil2_active': 23, 'vil3_active': 24, 'vil4_active': 25, 'vil5_active': 26, 'next_player': 27, 'next_player2': 28, 'next_player3': 29, 'next_player4': 30, 'next_player5': 31, 'last_agro_amount': 32, 'last_agro_action': 33, 'last_agro_position': 34, 'last_agro_is_blind': 35, 'hero_stack': 36, 'vil1_stack': 37, 'vil2_stack': 38, 'vil3_stack': 39, 'vil4_stack': 40, 'vil5_stack': 41, 'pot': 42, 'amount_to_call': 43, 'pot_odds': 44, 'previous_amount': 45, 'previous_position': 46, 'previous_action': 47, 'previous_bet_is_blind': 48}\n"
     ]
    }
   ],
   "source": [
    "print(game_states[0].shape)\n",
    "print(set(target_actions.tolist()))\n",
    "print(state_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out torch.Size([10595, 24, 11])\n",
      "2.520909547805786\n",
      "out torch.Size([10595, 24, 11])\n",
      "2.2540693283081055\n",
      "out torch.Size([10595, 24, 11])\n",
      "2.1148977279663086\n",
      "out torch.Size([10595, 24, 11])\n",
      "2.035886526107788\n",
      "out torch.Size([10595, 24, 11])\n",
      "1.975250482559204\n",
      "out torch.Size([10595, 24, 11])\n",
      "1.9303780794143677\n",
      "out torch.Size([10595, 24, 11])\n",
      "1.8890833854675293\n",
      "out torch.Size([10595, 24, 11])\n",
      "1.8523496389389038\n",
      "out torch.Size([10595, 24, 11])\n",
      "1.8216984272003174\n",
      "out torch.Size([10595, 24, 11])\n",
      "1.7929282188415527\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_network(training_params, game_states, target_actions, target_rewards,config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check predictions and visualize each poker situation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4080a1624ee4439a84e481bb4ede2655e1fa39fd626a6bd31d6205c13f8f417f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
